{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3174dcc5-3dfe-41ab-81d7-f7185d9182e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be focusing more on the activations and gradients, as well as, batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccebe1d9-df6a-4ef8-b0a1-797a731231af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d471a29-e7f6-4cfa-b4ec-016c01671136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all words\n",
    "words= open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85fb4586-e061-43fc-8efc-20c6cec05d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mapping to/from integers\n",
    "chars= sorted(list(set(''.join(words))))\n",
    "stoi= {s:i+1 for i,s in enumerate(chars)}\n",
    "# build special characters for the start and end\n",
    "stoi['.'] = 0\n",
    "itos= {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c97314c-84fb-4783-8ae5-f036b2bcf720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37cf73c0-0d3a-4953-b5e7-20a9809a3f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X, dtype=torch.long, device=device)\n",
    "  Y = torch.tensor(Y, dtype=torch.long, device=device)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "776f21a0-6945-4607-831b-a06267dbefee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12097 parameters in total\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# MLP Initialization (GPU version)\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# Embedding dimensionality: how many numbers represent each character.\n",
    "# Each character will be turned into a small dense vector of this size.\n",
    "n_embd = 10\n",
    "\n",
    "# Number of neurons in the hidden layer of the MLP.\n",
    "# This determines the model’s capacity (larger = more expressive, slower).\n",
    "n_hidden = 200\n",
    "\n",
    "# Create a random number generator on the same device for reproducibility.\n",
    "# Setting a fixed seed ensures consistent initialization and results.\n",
    "g = torch.Generator(device=device).manual_seed(2147483647)\n",
    "\n",
    "# Character embedding table:\n",
    "# Each of the 'vocab_size' possible characters gets a learnable embedding vector of size n_embd.\n",
    "# Using a normal distribution (randn) is common; its scale is fine since it's shallow.\n",
    "C = torch.randn((vocab_size, n_embd), generator=g, device=device)\n",
    "\n",
    "# First linear layer weights: transforms flattened embeddings into hidden-layer activations.\n",
    "# Shape = (input_dim, hidden_dim), where input_dim = n_embd * block_size - this is the FanIn.\n",
    "# The multiplier (5/3)/sqrt(input_dim) is from a scaled version of Kaiming/He initialization.\n",
    "# This scaling keeps the variance of activations roughly constant across layers, \n",
    "# which helps prevent exploding/vanishing activations when using tanh.\n",
    "# These numbers can be found within the PyTorch init documentation for the different activation functions\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g, device=device) \\\n",
    "     * (5/3) / ((n_embd * block_size) ** 0.5)\n",
    "\n",
    "# We do NOT need a bias vector 'b1' here because the BatchNorm layer that follows this linear layer\n",
    "# already has its own bias parameter ('bnbias'). BatchNorm can shift and scale activations directly,\n",
    "# making an explicit bias redundant. Including both would be unnecessary and slightly wasteful.\n",
    "#b1 = torch.randn(n_hidden,                        generator=g) * 0.01\n",
    "\n",
    "# Second linear layer weights: project from hidden layer to output vocabulary logits.\n",
    "# Initialized with a very small standard deviation (0.01) to keep early logits near zero.\n",
    "# This keeps the softmax output initially close to uniform and prevents overly confident predictions\n",
    "# before training adjusts the weights properly.\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g, device=device) * 0.01\n",
    "\n",
    "# Output layer bias: usually safe to initialize to zero.\n",
    "# This ensures all output classes start with equal prior probability.\n",
    "# Setting it explicitly to 0 avoids introducing bias toward any class at the start.\n",
    "b2 = torch.randn(vocab_size, generator=g, device=device) * 0\n",
    "\n",
    "# Small epsilon constant used in BatchNorm division to prevent division-by-zero.\n",
    "BN_EPS = 1e-5\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Batch Normalization parameters\n",
    "# ----------------------------------------------------------\n",
    "# Resolvin issues of layers chasing and trying to account for chaning input statistics = internal covariate shift\n",
    "\n",
    "# BatchNorm gain: a learnable scale factor applied after normalization.\n",
    "# Initialized to 1 so it starts as a no-op (doesn’t change the normalized output).\n",
    "bngain = torch.ones((1, n_hidden), device=device)\n",
    "\n",
    "# BatchNorm bias: a learnable shift parameter applied after normalization.\n",
    "# Initialized to 0 for the same reason as bngain — starts neutral.\n",
    "bnbias = torch.zeros((1, n_hidden), device=device)\n",
    "\n",
    "# Running mean: this tracks the moving average of activation means during training.\n",
    "# Starts at zero since we haven’t seen any batches yet.\n",
    "bnmean_running = torch.zeros((1, n_hidden), device=device)\n",
    "\n",
    "# Running standard deviation: tracks moving average of activation stds.\n",
    "# Starts at 1 so normalization doesn’t distort the activations before updates occur.\n",
    "bnstd_running = torch.ones((1, n_hidden), device=device)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Collect parameters for optimization\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# We include all learnable tensors that require gradients.\n",
    "# Note: bnmean_running and bnstd_running are buffers, not parameters — they’re updated manually.\n",
    "parameters = [C, W1, W2, b2, bngain, bnbias]\n",
    "\n",
    "# Print total number of parameters to get a sense of model size.\n",
    "print(sum(p.nelement() for p in parameters), \"parameters in total\")\n",
    "\n",
    "# Enable gradient tracking on all model parameters so autograd computes their gradients.\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa36bae0-a8e5-4b48-b818-f2a00d55da2c",
   "metadata": {},
   "source": [
    "### To understand BatchNormalization better\n",
    "\n",
    "Imagine your network’s layers are chefs in a kitchen, passing ingredients from one to the next.\n",
    "1. The first chef seasons the dish heavily.\n",
    "2. The second chef expects mild seasoning but gets a salty mess.\n",
    "3. The third chef has to adapt to that change.\n",
    "\n",
    "Training becomes unstable because every time one layer updates its weights, the “ingredients” (input distributions) that the next layer receives keep changing.\n",
    "\n",
    "BatchNorm acts like a quality control step between chefs:\n",
    "> It ensures the ingredients that move between layers have a consistent flavor profile — i.e., mean and variance.\n",
    "\n",
    "That stability lets each layer learn faster and more confidently.\n",
    "\n",
    "__It stops layers from constantly chasing each other’s changing input statistics — a problem called internal covariate shift.__\n",
    "\n",
    "#### For another Example of how it helps\n",
    "Imagine each neuron’s output as a microphone signal in a concert hall.\n",
    "- Without BatchNorm, some mics are whisper-quiet, others are blasting.\n",
    "- BatchNorm automatically adjusts the volume and tone of each mic (normalizing to 0 mean, 1 variance) before mixing.\n",
    "\n",
    "Then γ and β act as master volume and EQ knobs the system can fine-tune later.\n",
    "So BatchNorm doesn’t just normalize — it gives each neuron a consistent dynamic range.\n",
    "\n",
    "\n",
    "__The resulting goal of BatchNorm__\n",
    "- Ensure guassian results\n",
    "- This is to have mean roughly= 0 and mean roughly= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f10d2e55-0e1d-4d9d-954d-e52bc3f95d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 2.2891\n",
      "  10000/ 200000: 1.8151\n",
      "  20000/ 200000: 1.9947\n",
      "  30000/ 200000: 2.5741\n",
      "  40000/ 200000: 2.1072\n",
      "  50000/ 200000: 1.9162\n",
      "  60000/ 200000: 2.0888\n",
      "  70000/ 200000: 2.1648\n",
      "  80000/ 200000: 2.4825\n",
      "  90000/ 200000: 2.1105\n",
      " 100000/ 200000: 2.0634\n",
      " 110000/ 200000: 1.9858\n",
      " 120000/ 200000: 2.1463\n",
      " 130000/ 200000: 2.3579\n",
      " 140000/ 200000: 2.2095\n",
      " 150000/ 200000: 2.2276\n",
      " 160000/ 200000: 2.2728\n",
      " 170000/ 200000: 2.5307\n",
      " 180000/ 200000: 1.9972\n",
      " 190000/ 200000: 2.2361\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# OPTIMIZATION LOOP\n",
    "# ----------------------------------------------------------\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "# Make sure all model parameters are tracked for gradients\n",
    "parameters = [C, W1, W2, b2, bngain, bnbias]\n",
    "for p in parameters:\n",
    "    p.requires_grad_(True)\n",
    "\n",
    "## REFER1:\n",
    "# learning about a better way to use the decay on learning rate\n",
    "# learn more about the torch.optim\n",
    "import torch.optim as optim\n",
    "\n",
    "# Create the optimizer once before the loop\n",
    "optimizer = optim.SGD(parameters, lr=0.1)   # plain SGD\n",
    "# or optimizer = optim.Adam(parameters, lr=1e-3)   # adaptive variant\n",
    "\n",
    "# Optional scheduler to decay LR after 100 000 steps\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                           milestones=[max_steps/2],\n",
    "                                           gamma=0.1)\n",
    "\n",
    "# Training loop — computes forward pass, loss, backward, and update\n",
    "for i in range(max_steps):\n",
    "\n",
    "    # ---- Minibatch sampling ----\n",
    "    # Randomly pick a batch of indices from the training set.\n",
    "    # We draw directly on the GPU so tensors stay on the same device.\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g, device=device)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "\n",
    "    # ---- Forward pass ----\n",
    "    # Embed each token into its vector representation\n",
    "    emb = C[Xb]                                # Shape (B, T, E)\n",
    "    # Flatten the embeddings into a single vector per example\n",
    "    embcat = emb.view(emb.shape[0], -1)        # Shape (B, T*E)\n",
    "\n",
    "    # First linear transformation (input → hidden)\n",
    "    hpreact = embcat @ W1                      # Shape (B, n_hidden)\n",
    "\n",
    "    # ---- Batch Normalization (training mode) ----\n",
    "    # Compute mean and std for the current batch only.\n",
    "    # These statistics are used to normalize the activations, stabilizing training.\n",
    "    bnmeani = hpreact.mean(0, keepdim=True)\n",
    "    bnstdi  = hpreact.std(0, keepdim=True, unbiased=False)\n",
    "    hpreact = bngain * (hpreact - bnmeani) / (bnstdi + BN_EPS) + bnbias\n",
    "\n",
    "    # Update the running mean/std used later for inference (exponential moving average).\n",
    "    # We do this inside torch.no_grad() because we don't want autograd to track it.\n",
    "    with torch.no_grad():\n",
    "        bnmean_running.mul_(0.999).add_(0.001 * bnmeani)\n",
    "        bnstd_running.mul_(0.999).add_(0.001 * bnstdi)\n",
    "\n",
    "    # ---- Non-linearity ----\n",
    "    h = torch.tanh(hpreact)                    # Apply activation function\n",
    "    # Output layer (hidden → vocab logits)\n",
    "    logits = h @ W2 + b2\n",
    "    # Cross-entropy automatically applies log-softmax and NLL\n",
    "    loss = F.cross_entropy(logits, Yb)\n",
    "\n",
    "    # ---- Backward pass ----\n",
    "    # for p in parameters:\n",
    "    #     p.grad = None                          # Zero gradients before backward\n",
    "    optimizer.zero_grad(set_to_none=True)   # faster than manual loop\n",
    "    \n",
    "    loss.backward()                            # Compute gradients\n",
    "\n",
    "    # ---- Parameter update ----\n",
    "    # # Manual SGD update under torch.no_grad() so it’s not tracked by autograd.\n",
    "    # lr = 0.1 if i < 100000 else 0.01\n",
    "    ## THE UPDATED SECTION IS IN REFER1\n",
    "    optimizer.step()\n",
    "    scheduler.step()                        # adjusts LR if using scheduler\n",
    "\n",
    "    ## SECTION BELOW COMMENTED OUT checkot REFER1\n",
    "    # with torch.no_grad():\n",
    "    #     for p in parameters:\n",
    "    #         p -= lr * p.grad                   # Weight update (in-place)\n",
    "\n",
    "    # ---- Logging ----\n",
    "    if i % 10_000 == 0:\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e7d2a66-582c-4c0e-a462-ac6b856eb669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7d8d0c204a30>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71578cab-4f0c-440d-ad75-66c3a5f02420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# BATCH NORM CALIBRATION AFTER TRAINING\n",
    "# ----------------------------------------------------------\n",
    "# At the end of training, we compute the true mean and std of the hidden layer\n",
    "# across the entire training set. This ensures consistent normalization at inference.\n",
    "# This isn't additional training - hence appointed by the no_grad. This is just running the full dataset (XTr) to see results\n",
    "with torch.no_grad():\n",
    "    emb     = C[Xtr]                           # Forward full training set\n",
    "    embcat  = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1\n",
    "    bnmean  = hpreact.mean(0, keepdim=True)    # True dataset mean\n",
    "    bnstd   = hpreact.std(0, keepdim=True, unbiased=False)  # True dataset std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "958aa9db-e1a1-4bb5-8099-08f3f5ecf746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.0687103271484375\n",
      "val 2.1125259399414062\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# LOSS EVALUATION FUNCTION\n",
    "# ----------------------------------------------------------\n",
    "# The @torch.no_grad() decorator disables autograd tracking.\n",
    "# This saves memory and computation when gradients aren't needed.\n",
    "# Here, we evaluate model loss for train/val/test splits.\n",
    "@torch.no_grad()\n",
    "def split_loss(split):\n",
    "    # Select which dataset split to use\n",
    "    x, y = {\n",
    "        'train': (Xtr,  Ytr),\n",
    "        'val':   (Xdev, Ydev),\n",
    "        'test':  (Xte,  Yte),\n",
    "    }[split]\n",
    "\n",
    "    # Forward pass identical to training, except we use stored BN stats\n",
    "    emb     = C[x]\n",
    "    embcat  = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1\n",
    "\n",
    "    # Use running mean/std for evaluation (or use bnmean/bnstd if calibrated)\n",
    "    hpreact = bngain * (hpreact - bnmean_running) / (bnstd_running + BN_EPS) + bnbias\n",
    "\n",
    "    h      = torch.tanh(hpreact)\n",
    "    logits = h @ W2 + b2\n",
    "    loss   = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "\n",
    "# Compute and print evaluation losses\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ee0bf2d-f8ea-480a-b97b-bca7ed74da71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yoznave.\n",
      "annislda.\n",
      "nevan.\n",
      "ariya.\n",
      "aoluwa.\n",
      "lekansh.\n",
      "nia.\n",
      "elaiya.\n",
      "quid.\n",
      "kritalia.\n",
      "elanna.\n",
      "zae.\n",
      "johaida.\n",
      "khuya.\n",
      "kaelie.\n",
      "ben.\n",
      "leya.\n",
      "alynleer.\n",
      "sky.\n",
      "cassi.\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()  # disable gradient tracking — sampling doesn't need grads\n",
    "def sample_name(block_size, itos, use_calibrated=True, max_steps=100):\n",
    "    \"\"\"\n",
    "    Generate a new sample (e.g., a name) one token at a time.\n",
    "    Arguments:\n",
    "      block_size: how many preceding characters to condition on\n",
    "      itos: index-to-string mapping for decoding\n",
    "      use_calibrated: if True, use the full-dataset mean/std computed earlier\n",
    "      max_steps: safety cap on sequence length\n",
    "    \"\"\"\n",
    "    # Start with a context of all '.' tokens (index 0), on the GPU\n",
    "    context = torch.zeros((1, block_size), dtype=torch.long, device=device)\n",
    "    out = []\n",
    "\n",
    "    while True:\n",
    "        # Embed the current context\n",
    "        emb     = C[context]                      # Shape (1, T, E)\n",
    "        B, T, E = emb.shape\n",
    "        embcat  = emb.view(B, T * E)\n",
    "\n",
    "        # Compute hidden activations\n",
    "        hpreact = embcat @ W1\n",
    "\n",
    "        # Normalize using calibrated or running batch norm stats\n",
    "        if use_calibrated:\n",
    "            hpreact = bngain * (hpreact - bnmean) / (bnstd + BN_EPS) + bnbias\n",
    "        else:\n",
    "            hpreact = bngain * (hpreact - bnmean_running) / (bnstd_running + BN_EPS) + bnbias\n",
    "\n",
    "        # Nonlinearity + output projection\n",
    "        h      = torch.tanh(hpreact)\n",
    "        logits = h @ W2 + b2\n",
    "        probs  = F.softmax(logits, dim=1)         # Convert logits → probabilities\n",
    "\n",
    "        # Randomly sample the next token index from the predicted distribution\n",
    "        ix = torch.multinomial(probs[0], num_samples=1, generator=g).item()\n",
    "\n",
    "        # Append token and update context (keep same block_size)\n",
    "        out.append(ix)\n",
    "        new_ix = torch.tensor([[ix]], dtype=torch.long, device=device)\n",
    "        context = torch.cat([context[:, 1:], new_ix], dim=1)\n",
    "\n",
    "        # Stop if we generate the '.' token (index 0) or reach the limit\n",
    "        if ix == 0 or len(out) >= max_steps:\n",
    "            break\n",
    "\n",
    "    # Convert numeric indices back into characters and join them into a string\n",
    "    return ''.join(itos[i] for i in out)\n",
    "\n",
    "# Generate several samples\n",
    "for _ in range(20):\n",
    "    print(sample_name(block_size, itos, use_calibrated=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70f4d35d-8abd-413f-ab36-c0d016970082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2958)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The initial loss has not been bad, but we can optimize further for initialization of weights\n",
    "# initiial we want to aim for something like below\n",
    "-torch.tensor(1/27.0).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb0c360-d537-4150-a16a-54d1c43c22d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4d of issue\n",
    "logits = torch/ten"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nn-env)",
   "language": "python",
   "name": "nn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
